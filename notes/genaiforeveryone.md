# 人人都能用的生成式 AI（Generative AI for Everyone）课程学习笔记

## 生成式 AI 的工作原理是什么样的？

类似 ChatGPT 的生成式 AI 能输出极为生动、逼真的文本，这得益于大型语言模型（LLMs）。这些模型是通过海量的文本数据训练出来的。

下面这个简单的例子可以说明它的工作原理：假设你给模型输入了一句 "我最爱的食物是一个贝果搭配..."。模型已经处理过成千上万类似的句子，它知道 "贝果搭配" 之后通常接的是 "奶油芝士"，于是它极可能会预测下一个词是 "奶油芝士"。

借助庞大的文本数据集训练，AI 掌握了文本中的一些规律，知道哪些词常常会紧跟在什么词后面。

所以生成式 AI 在输出的时候，它就是在所有过往接触过的文本例子中，或者说它掌握的语言的规律中，预测出可能性最高的下一个词。所以它能够在任何主题上跟你侃大山。

要注意的是，有时它可能会幻想出一些事实（Hallucination），或者给出错误信息。这点是要牢记的。

## 可以把生成式 AI 当作一个头脑风暴助手

试想一下，有一个智能助手能帮你分析复杂问题，并想出一些创新的解决方案。这该有多好。我们知道，头脑风暴，主要讲究一个风暴嘛，先不论对错。

举例来说，如你拿不准主意如何修改一段文字以使其表达得更加清晰，你便可以问问生成式 AI。

又或者，如你想随手写一个有趣的小故事来逗小孩，你只需给生成式 AI 输入一些关键词，它就可以为你创作一个全新的故事。

因此，下次你想要激发想法或是想换个角度看问题，不妨尝试与生成式 AI 交流一番。可能会有惊喜等着你。

## 生成式 AI 有什么用处？

生成式 AI 就象电或者互联网一样，可以把它看作是一种通用的基础设施，能协助我们完成各种不同的任务。就如我们利用电力来驱动各类提升生活品质的设备和器械一样，生成式 AI 能生成文本，理解语言，进行对话。

比方说，在你写作时，它可以帮助你产生创意，通过搜索信息来回答你的问题，或者像一个贴心的助手那样进行自然对话。


## 用生成式 AI 辅助写作

你可以直接告诉生成式 AI，要它写一个什么报告或者文章。一开始它写出来的东西，可能很套话，是比较通用的模板。

那么，接下来就可以调整你的提示词，比如提供你要它的写的主题的背景和上下文，以及你的用途，希望它用什么样的语言风格来写。

根据 AI 的输出结果来迭代你的提示词。类似“帮我写一篇微信公众号爆款文章”这样的提示词，自然很难得到预期的结果。

我们自己得知道我们要什么，然后告诉它。

哪怕最后发现它实在不能完美胜任某个写作任务，我相信基于它的回复去优化去调整，或者借鉴一些素材还是没问题的。

## 把生成式 AI 当作阅读助手

想象一下，你写了一篇文章，尤其是英文，想确保它没有拼写、语法或句子结构上的错误。发给生成式 AI，让它来检查。有时候只需要简单地说 Please proofread the following text: "Your texts."，它就能帮你很好地润色一版。

针对不同的场景，你还可以要求它按照某种语气来重写。

另一个用处是对长文做总结。把长文发给 AI，让它总结。这样，你可以在不花费太多时间阅读的情况下了解文章的要点。

又或者是做一些语义分析。比如分析评论的感情色彩是正面还负面，分析客户的反馈应该归类到什么主题以及建议分发给哪个部门来处理等等。

## 把生成式 AI 当作聊天机器人

最常见的就是可以把它训练为特定领域的客服，可以回答一些常规的、简单的问题。减轻客服人员压力。只有在遇到它不能回复的问题的时候，再转人工。这里面要关注的就是安全性和准确性的问题。

一般来说某些环节需要人工参与，来验证 AI 的回复，确认之后再输出给客户。


## 生成式 AI 能做什么和不能做什么？

它虽然很厉害，可以根据输入生成类似真人回复的文本。可以把它们想象成是刚刚毕业的大学生，具有一般性基础知识，但没有在特定领域接受过专门培训。

它们可以根据从大量文本数据中学到的知识提供信息并回答问题，但是它们也有局限性。

牢记它们可能会胡编乱造，我们称之为“幻觉”。同时，要注意它们在输入和输出长度上有限制。它们在处理结构化数据（如表格或数据库）方面存在困难，而在处理非结构化信息（如文本）方面表现更好。


## 写提示词的原则

1. 提供详细和具体的信息：提供足够的背景和上下文信息有助于语言模型更好地理解任务。详细描述所需的任务可能会让 AI 的输出更符合你的预期；

2. 引导模型思考其回答：给予逐步指导可以帮助语言模型按照特定的过程生成期望的输出。通过将任务分解为较小的步骤，引导模型朝着期望的结果来回复；

3. 实验和迭代：提示是一个迭代的过程。重要的是尝试不同的提示，一开始你可以只写一个最基本最简单的提示，如果结果不令人满意，然后根据初始结果进行调整和改进。可能需要多次迭代才能实现期望的结果。

对于一些重要的结果，一定想办法做交叉验证。比如用其他权威的信息源来验证 AI 的输出结果。

一个小技巧，思考一个刚毕业的大学生，能不能按照我们写的提示词的指导来完成任务？如果答案是可以，那么 AI 也大概率能理解我们的提示词。

## 文本生成图片的原理

文字生成图片的 AI 模型是通过使用大量的图像来训练一种特殊的算法，称为扩散模型 (Diffusion Model)。训练过程主要是逐渐向图像添加噪点，使其最后看起来像是随机像素点一样，然后再用算法一步步去除噪点把图像还原。

相当于告诉 AI 这张图是如何组成的。

要从文本生成图像，AI 会从一个完全随机的全是噪点的图片开始。然后，将这个图片连同我们的提示词或描述一起提供给训练过的 AI 模型。

模型通过它训练时学会的规律，通过一步步去除噪点使最后生成的图片符合我们的描述。

例如，如果我们想生成一个绿色香蕉的图片，AI 会从全是噪点的图片和提示词“绿色香蕉”开始，先创建一个粗略的绿色水果的表现，并通过每次迭代改进图像，直到获得一个清晰的绿色香蕉的图片。

## 基于生成式 AI 构建产品的流程以及调优策略

基于生成式 AI 构建产品是一个迭代的过程，涉及到确定项目范围、构建原型、内部评估和部署。不过我想，无论基于什么技术构建产品，都是一个持续迭代的过程。

但现在基于生成式 AI 来构建一个产品变得前所未有的容易。我们可以快速地实验我们的想法。

持续调优基于生成式 AI 产品的工具/策略：

1. Prompting: 也就是大家所熟知的提示词工程，不断地优化提示词来提升生成式 AI 回复的精确性；

2. RAG (Retrieval Augmented Generation 检索增强生成) : 通过外部数据源给 AI 模型提供针对任务的有效数据和信息，使其能更好地完成任务;

3. Fine-tuning (微调) ：通过为特定任务准备相关的数据集让 AI 模型学习，以提升其完成特定任务的精确性；

4. 预训练模型: 自己训练一个专属模型，比如用某个垂直领域内的知识库来训练。


## 基于生成式 AI 构建产品的费用

不考虑带宽、服务器等其他因素，如果我们使用 OpenAI 或者微软的 Azure 服务来使用调用 AI 模型，主要的费用就是 token，包括输入和输出。输入是我们发送给 AI 模型的数据，输出指的是 AI 模型的回复。

什么是 token？

就像我们能够以字为单位来拆分一段文字，基于 LLM (大语言模型) 的生成式 AI 则是以 token 为单位来拆分的。可能一个英文单词是一个 token，也可能被拆分为多个 token.

比如，Andrew 是一个常见的名字，可能会被当作一个 token，而 translate，则可能被拆成两个 token, tran + slate.

token 与单词可以粗略换算。1000 tokens ≈ 750 个英文单词  ≈ 450 个中文字符。(tokens 和英文单词的换算，OpenAI 官方文档有提及，与中文的换算是我读到的网上的通用说法，具体在使用的时候，可以通过工具来计算。OpenAI 就有 tokenizer 可以计算实际的 token)

## Retrieval Augmented Generation (RAG) 策略

RAG 是一种给生成式 AI 模型提供额外的上下文信息/数据的一种策略。这些上下文信息可以是公司的内部知识库，也可以是通过外部工具获取的实时信息。

简而言之，RAG 更多可以看作是一种策略，而不是某种具体的技术。目的就是为特定的任务/问题提供相关的、 AI 模型可能本身没有的信息。

比如那些 PDF 阅读助手通常可以使用 RAG 策略，也就是基于文档内容来和我们对话。

类似还有 Bing Chat 或者 Google Bard 这样的，天然地可以使用搜索引擎的数据来应用 RAG 策略。

一个很重要的思路：把生成式 AI 当作推理引擎，而不是一个知识百科。尽管它确实知道很多知识。

## Fine-tuning (微调)

什么是微调？

微调同样是一种给 AI 提供数据的方式，以提升处理特定任务的精确性。可以把上面的 RAG 看作一种针对任务提供临时相关信息的方式，微调则是让 AI 学会新的知识。

什么时候会用到微调？

1. 当一个任务无法通过写 prompt 完成时，可能需要微调。比如想让 AI 的回复能模仿某个人的说话方式和语气，那么可以用这个人的演讲稿、笔记等一系列数据，通过微调，让 AI 从这些数据里学会这个人的讲话方式；

2. 要让 AI 学会垂直领域里的专门知识。比如会使用大量专业术语以及特定的表达方式的领域，医学报告、法律文书等；

3. 在上面的 RAG 策略中，Andrew 提到了一个重要的思路。即把生成式 AI 当作推理引擎。

那么，当一个模型的目标是完成某些特定领域里的任务的时候，就不需要使用一个通用的、可能拥有上千亿参数的大模型。

而是基于一个更小的模型来进行微调。这样可以微调出一个运算更快、体积更小的 AI 模型，尤其是要让这个 AI 模型跑在一些手机或平板这类个人设备上的时候，微调策略就很有用；

## 自己从头训练一个模型

这通常是以上策略都无法很好地完成指定任务的时候才会用。没海量的数据，别想这事儿；没钱，也别想这事儿。这是个费时、费力、费钱的活 ^_^

更常见的方式，是基于一个已有的模型来做训练，比如 Meta 或者其他公司开源的模型。

## 如何选择模型？

首先是模型大小，如果只是要做一些基本分类识别、语义情感色彩分析，可能一个 10 亿参数的模型就够了。配合以上的 RAG 或微调，应该能很好地完成类似的模式识别类的任务。

如果要让模型具备理解一些指令步骤，来实现一个特定场景的聊天机器人 (比如点外卖的机器人)，可能需要考虑 100 亿参数的模型。

针对再复杂一点的，需要借助许多领域知识 (哲学/物理/科学等等) 进行推理的任务，可能就得上 1000 亿参数的模型了。

选开源模型还是不开源的商业模型？

这取决于具体情况，要考虑研发成本，模型完成目标任务的有效性，以及数据隐私方面的问题。

## LLM (大语言模型) 是如何理解指令的？指令微调以及 RLHF (Reinforcement Learning from Human Feedback)

生成式 AI 回复的时候，实际上是它根据海量文本训练中学会的规律，预测出可能性最高的下一个词。

如果希望 AI 模型在回复某类问题的时候，采用一种特定的回复结构，除了每次在 prompt 中给例子 (Few-shot) 这种方式以外，就是用指令微调策略。

和微调类似，给它大量的问题和回复模板数据让它学习，来实现以特定的回复结构输出。

RLHF，是基于反馈的强化学习。就是告诉如何 AI 区分回复的质量高低，然后引导它去生成更高质量的回复。实现这个策略的步骤：

1. 首先基于监督学习训练一个打分模型或者说奖励模型。这个模型能够对问题及其不同的答案分别进行打分；

2. 用奖励模型进行强化学习。让 AI 尝试针对问题生成各种各样的答案，结合奖励模型，AI 能够知道自己生成的答案里哪个更好，并尝试在下一次生成更高质量的回复；

3. 不断迭代上述过程，以提升 AI 的回复质量。

强化的过程可以简单类比为巴甫洛夫训练他的狗，核心是建立行为和奖惩之间的联系，以调整其行为。他首先在给食物的同时摇响铃声，而狗会因为看到食物而流口水。

不断重复这个过程后（强化学习），狗就将铃声与得到食物 (奖励) 相联系，于是以后当铃声响起时，狗就会流口水，即使没有食物。


## Agents

很多时候，以生成式 AI 为基础，配合外部工具，能更有效和准确地完成任务。比如，生成式 AI 有时候小学数学题都会做错，甚至数单词数或字数都会数错。这也是很多人觉得生成式 AI 智障的主要原因。

除了一些 prompt 技巧和对话的技巧，我们完全可以把它目前不擅长的任务外包出去。不擅长计算，就借助外部的计算器，不擅长数单词，就借助外部的字符统计器。

总之，它做它擅长的 (推理)，不擅长的交给其他人来做。

为特定的任务规划一套解决方案，LLM、搜索引擎、各种工具，它们各司其职又互相协作，最后为特定的任务交付一个高质量的结果。我想，这就是 Agents 吧。

## 把工作拆分为更小的具体任务

一项工作实际上是由一系列任务组成，利用 AI 来提效，从具体任务的视角来分析，是更好的方式。

思考工作环节的哪些任务，可以交给现在的 AI 来做。它现在的能力可以做到什么程度？怎么把它无缝融入到工作流中？

也就是说把 AI 当作新工具，不用神话它，但也不要忽视它。如果它确实不能对当前手上具体的工作任务产生实际的价值，那不用就好了。让子弹飞一会儿，或许几个月后，几年后，它成长了，它又行了。

## 如何分析 AI 对于具体任务的应用潜力？

和应用任何新技术、新方案一样，都要考虑各种因素。Andrew 老师在课程中提了两个视角。基于对具体任务的分析，评估技术上的可行性和商业价值。

也就是说，我们需要思考，AI 能在多大程度上帮我降本增效？而我要付出多大的成本来使用它？是谓性价比分析。

## 写提示词 (prompt) 是叠 buff

如课程第二部分里提到的各种工具和策略，优化生成式 AI 完成指定任务的效果有很多方式，RAG、微调、优化提示词等。

写提示词是更好入门，也是直观地感受生成式 AI 能力的一种方式。基于自己的场景和知识积累去用，叠一层 buff. 软件工程师可以通过写提示词，辅助自己写一些代码，产品经理可以写提示词来辅助自己头脑风暴，每个人都可以通过写提示词打造自己的学习助手......

## 关于 AI 的担忧

一个是偏见问题。可能是性别上的偏见，也可能是 polity 方面的偏见。因为生成式 AI 的模型基于互联网上的几乎所有数据来训练，表现得博学的同时，也会把其中的在特定环境下不正确的方面暴露出来。

减少 AI 模型的偏见，可以通过课程第二部分提到的微调和 RLHF 策略，让 AI 模型表现得更符合特定上下文的正确。

另一个担忧是 AI 可能造成一部分人失业的问题。这个问题太复杂。课程里举了一个例子，2016 年，AI 领域的领军人物之一，Geoff Hinton 预言 5 年内，放射科医生就要失业。因为 AI 能够完全做好这些医生的工作。

从现在的结果来看，放射科医生并没有被 AI 替代。主要原因在于上面提到过的一个职业或者说工作岗位，通常牵涉到一系列具体的任务。

除非 AI 能够做好这个岗位里的所有任务，或者至少是最核心的任务，才可能产生对这个职业的替代。就其他情况来说，AI 是更好的一种工具。

另一个常常被提起的但又无法证伪的担忧，则是 AI 会毁灭人类。关于这个担忧，Andrew 在 The Batch (2023-10-25) 里谈过。那些持有这种观点的人，更多是含糊其辞。


## AGI (Artificial General Intelligence)

定义：AI 可以完成所有人类智力能做到的事情。比如像人类一样拿博士学位，像一个程序员一样可以写复杂的程序来完成特定的任务等。

目前的 AI 技术离 AGI 还有不小的距离。参考图九，来自 Google DeepMind 发布的一篇论文。根据这个分级，ChatGPT 算是处在第一级。

最后附上我喜欢的一句结束语：
AI has the potential to give every individual the ability to hire intelligence at low cost.
(AI 使得每个人都能以较低的成本使用各种智能服务)

借用吴军老师在《全球科技通史》中的一句话：历史总在重演，科技永远向前。

原课程链接：[Generative AI for Everyone](https://www.coursera.org/learn/generative-ai-for-everyone/home/week/1)
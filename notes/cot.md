# 8 个 CoT (Chain of Thought) 技巧总结

最近读了 10 来篇关于 CoT (Chain of Thought) 的论文。CoT 可以说是写提示词里最重要的技巧之一，所以我想了解那些顶级的工程师、团队都提出了哪些实现 CoT 的具体方法，而更重要的是，哪些方法是直接可以在提示词层面使用的。

毕竟，对于像我一样的普通用户来说，提示词是最容易上手的，性价比最高。至于有些思路/框架，是要在工程方面去解决的，就留给工程师们吧。

目前读到的、我能大概理解的 CoT 技巧有这几种：Zero-shot-CoT、Manual CoT、Self-Consistency CoT、Auto CoT、Meta CoT、Least-to-Most CoT、LogiCoT、CoVe CoT。

一共 8 个，就叫它 CoT 里的八奇技......吧。

## Zero-shot-CoT

性价比之神。在提示词里加上简单的一句“Let's think step by step.”即可让 AI 按照一步步推理的方式来回答问题。

有不少论文指出在特定的 AI 模型和特定的问题类型上，使用其他的语句比“Let's think step by step.” 更好。但我个人还是常用这个。除非我发现输出结果明显不对，我就会换用其他语句试试。

这里还有其他 6 种类似的神奇语句（中英对照）：[Zero-shot-CoT 触发词](./zero_shot_cot_triggers.md)

建议在用这些语句的时候，直接使用英文，不要翻译成中文。因为论文数据是严格地使用这些英文句子的，而有些英文句子看起来表达的其实是一个意思，但对 AI 模型来说，就是不一样。没有对照数据表明翻译成什么样的中文能达到一样的效果。

## Manual CoT

这个也叫 Few-shot-CoT，可以说是 Zero-shot-CoT 的加强版。就是给 AI 模型打个样，告诉它该如何解题。比如在让它回答某个问题之前，先给它发几个类似的问题以及问题的解题过程和答案。AI 会从这样少量的例子里学到一些规律，用于解新的题。效果倍儿棒，性价比之王。

## Auto CoT

Manual CoT 的升级版。Manual CoT 要我们针对问题亲自给 AI 打样，Auto CoT 就是自动档。在解题前，自己给自己先打样，再解题。但这个方式的前提是有针对问题归类好的数据集。因为 AI 需要从数据集里查询相似的问题来打样。需要工程方面解决。

因此，不适合在提示词层面使用。而且我看论文测试数据，结果相比 Manual CoT 提升不是特别明显，约 5% 左右。

## Meta CoT

Auto CoT 的 Pro 版。核心思路是认为 Auto CoT 有时候自动打样打得不咋滴，于是在从数据集查询相关样例之前，先对问题本身进行场景识别。比如说识别问题是数学题、符号推理还是常识性问题，以及要求的答案类型是多项选择、是非还是其他类型。同样需要工程方面解决。提示词层面不太能直接用得上。

## Least-to-Most

Least-to-Most 是教育心理学里的一个概念。意思是通过循序渐进的提示，逐步引导学生掌握目标技能。这个与其说是一种技巧，不如说是一种思维方式。核心是把问题拆解成一个个的子问题，并且每一个子问题的答案是有助于解决下一个子问题的。

我觉得这是一个可以在提示词层面使用的非常好的方法。具体的应用并不难，提示词类似：“要解决 XXX 问题，需要知道如下问题的答案：1:Q1  2: Q2”，又或者是“让我们来拆分一下这个问题：1:Q1  2: Q2”，然后再让 AI 给出最终答案。

借用论文中的一个例子来帮助我们理解如何在提示词层面应用。

提示词 (prompt)：Elsa 有 5 个苹果。Anna 比 Elsa 多 2 个苹果。他们一共有多少个苹果？
让我们分解一下这个问题：

1. Anna 有多少个苹果？
2. Elsa 和 Anna 一共有多少个苹果？

AI 可能输出的答案形式：
Anna 比 Elsa 多 2 个苹果。所以 Anna 有 2 + 5 = 7 个苹果。
Elsa 和 Anna 一共有 12 个苹果。

所以，我们可以看到，Least-to-Most 实际上是我们在帮助 AI 去更好地理解问题，并且减少推理的难度和单次推理的计算量，以便 AI 能得出更精确的结果。难的不是如何用这个技巧，而是在用的时候，如何拆解问题。

## Self-Consistency CoT

让 AI 模型针对问题生成不同的推理路径或者说解题思路，得出一个结果集，最后选择占多数的那个的答案。比如让三个水平差不多的学生解同一道题，他们的思路可能各不相同，两个同学得出答案是 6，一个同学得出答案是 8。那么 6 这个答案可能更 6 一些，是正确答案的概率更高。

具体实现是通过修改 AI 模型的生成文本的取样算法（Sampling method）。

我看了一下，取样算法有这些：Nucleus sampling、Contrastive decoding、Speculative sampling、Top-K sampling、Greedy decoding.

我也不知道什么意思，我复制的。试图理解，看了两分钟，关掉了网页。

但是，我们仍然可以在提示词层面使用这个技巧。一种是通过设置 AI 模型的 temperature 值。比如 Poe 里自己创建的机器人 (Bot) 是可以自己手动设置 temperature 值的。设置不同的三个 temperature 值，发送相同的 prompt，最后来对比答案。

也可以使用 Bing，Bing 有三种模式：创造力、平衡、精确。我想意思应该差不多。

## LogiCoT

其核心思想是对 CoT（Chain-of-Thought）的每一步推理结果进行二次校验，校验完对这一步的推理过程进行修正，然后重新让 AI 按照新的步骤推理。这种方式如果用提示词来实现，提示词会非常长，都有可能超出会话上下文。

在进行二次校验的时候，思路是让 AI 自己针对指定的步骤，从两个不同的角度进行评审，然后依次分析，最后给出它认为更可信的角度。我基于这个思路写了一个让 AI 自己校验答案的提示词。详情见：[](../prompt_eval/result_eval.md)

## CoVe CoT

思路和 LogiCoT 有点像。其核心思路是从 AI 的回复中抽取关键的事实，然后针对这些事实生成一系列问题让 AI 自己回答，最后再汇总输出最终回复。

有点像老师让学生在做完题后，针对关键步骤再仔细检查一遍，看看有没有哪个环节做错了。

最后，综合这八奇技来看，能在提示词层面方便应用，并且效果显著的是这 4 个：Zero-shot-CoT、Manual CoT、Self-Consistency CoT、Least-to-Most CoT.